#!/usr/bin/env python3
"""
å¹¶è¡Œæ‰§è¡Œå™¨ - AlphaZero é£æ ¼è‡ªåšå¼ˆå­¦ä¹ ç³»ç»Ÿ

åŠŸèƒ½ï¼š
1. å¹¶è¡Œæ‰§è¡Œå¤šä¸ªç­–ç•¥å˜ä½“
2. æ”¶é›†å’Œå¯¹æ¯”æ‰§è¡Œç»“æœ
3. é€‰æ‹©æœ€ä¼˜ç­–ç•¥
4. æ›´æ–°ç­–ç•¥æƒé‡
"""

import json
import asyncio
import time
from typing import List, Dict, Any, Optional
from pathlib import Path
from datetime import datetime


class ParallelExecutor:
    """å¹¶è¡Œæ‰§è¡Œå™¨ - ä½¿ç”¨ asyncio å®ç°çœŸæ­£çš„å¹¶è¡Œ"""

    def __init__(self):
        self.results_dir = Path(__file__).parent.parent / "execution_results"
        self.results_dir.mkdir(exist_ok=True)

    async def execute_variants(
        self,
        variants: List[Dict[str, Any]],
        task_description: str
    ) -> List[Dict[str, Any]]:
        """
        å¹¶è¡Œæ‰§è¡Œå¤šä¸ªç­–ç•¥å˜ä½“

        Args:
            variants: ç­–ç•¥å˜ä½“åˆ—è¡¨
            task_description: ä»»åŠ¡æè¿°

        Returns:
            æ‰§è¡Œç»“æœåˆ—è¡¨
        """
        print(f"\nğŸš€ å¼€å§‹å¹¶è¡Œæ‰§è¡Œ {len(variants)} ä¸ªç­–ç•¥å˜ä½“...")
        print(f"ğŸ“ ä»»åŠ¡æè¿°: {task_description}\n")

        # åˆ›å»ºå¹¶è¡Œä»»åŠ¡
        tasks = []
        for i, variant in enumerate(variants):
            task = self._execute_single_variant(
                variant_id=i + 1,
                variant=variant,
                task_description=task_description
            )
            tasks.append(task)

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        start_time = time.time()
        completed_tasks = await asyncio.gather(*tasks, return_exceptions=True)
        total_duration = time.time() - start_time

        # æ”¶é›†ç»“æœ
        results = []
        for i, result in enumerate(completed_tasks):
            if isinstance(result, Exception):
                results.append({
                    "variant_id": i + 1,
                    "variant_name": variants[i]["name"],
                    "success": False,
                    "error": str(result),
                    "duration": 0,
                    "quality_score": 0
                })
            else:
                results.append(result)

        print(f"\nâœ… æ‰€æœ‰å˜ä½“æ‰§è¡Œå®Œæˆï¼Œæ€»è€—æ—¶: {total_duration:.2f}ç§’\n")

        # ä¿å­˜ç»“æœ
        self._save_results(results, task_description)

        return results

    async def _execute_single_variant(
        self,
        variant_id: int,
        variant: Dict[str, Any],
        task_description: str
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•ä¸ªç­–ç•¥å˜ä½“

        Args:
            variant_id: å˜ä½“ID
            variant: ç­–ç•¥å˜ä½“é…ç½®
            task_description: ä»»åŠ¡æè¿°

        Returns:
            æ‰§è¡Œç»“æœ
        """
        variant_name = variant["name"]
        print(f"ğŸ”„ å˜ä½“ {variant_id} ({variant_name}) å¼€å§‹æ‰§è¡Œ...")

        start_time = time.time()

        try:
            # æ¨¡æ‹Ÿæ‰§è¡Œï¼ˆå®é™…åº”è¯¥è°ƒç”¨ Claude Code çš„ background_task APIï¼‰
            result = await self._simulate_execution(variant, task_description)

            duration = time.time() - start_time

            # è®¡ç®—è´¨é‡åˆ†æ•°
            quality_score = self._calculate_quality_score(result, variant)

            print(f"âœ… å˜ä½“ {variant_id} ({variant_name}) æ‰§è¡Œå®Œæˆ - å¾—åˆ†: {quality_score:.1f}/10")

            return {
                "variant_id": variant_id,
                "variant_name": variant_name,
                "success": True,
                "duration": duration,
                "quality_score": quality_score,
                "result": result,
                "config": variant["config"]
            }

        except Exception as e:
            duration = time.time() - start_time
            print(f"âŒ å˜ä½“ {variant_id} ({variant_name}) æ‰§è¡Œå¤±è´¥: {str(e)}")

            return {
                "variant_id": variant_id,
                "variant_name": variant_name,
                "success": False,
                "duration": duration,
                "quality_score": 0,
                "error": str(e)
            }

    async def _simulate_execution(
        self,
        variant: Dict[str, Any],
        task_description: str
    ) -> Dict[str, Any]:
        """
        æ¨¡æ‹Ÿæ‰§è¡Œï¼ˆå®é™…åº”è¯¥è°ƒç”¨ Claude Code APIï¼‰

        Args:
            variant: ç­–ç•¥å˜ä½“
            task_description: ä»»åŠ¡æè¿°

        Returns:
            æ‰§è¡Œç»“æœ
        """
        # æ¨¡æ‹Ÿæ‰§è¡Œæ—¶é—´ï¼ˆæ ¹æ®å¹¶è¡Œåº¦è°ƒæ•´ï¼‰
        parallel_degree = variant.get("parallel_degree", "medium")
        if parallel_degree == "high":
            await asyncio.sleep(1.0)  # é«˜å¹¶è¡Œåº¦ï¼Œå¿«é€Ÿå®Œæˆ
        elif parallel_degree == "medium":
            await asyncio.sleep(1.5)  # ä¸­ç­‰å¹¶è¡Œåº¦
        elif parallel_degree == "low":
            await asyncio.sleep(2.0)  # ä½å¹¶è¡Œåº¦ï¼Œæ…¢é€Ÿå®Œæˆ
        else:
            await asyncio.sleep(1.2)  # è‡ªé€‚åº”

        # æ¨¡æ‹Ÿæ‰§è¡Œç»“æœ
        return {
            "files_modified": 5,
            "tests_passed": 8,
            "tests_failed": 0,
            "code_quality": 8.5,
            "agent_coordination": 7.8,
            "task_completion": 9.0
        }

    def _calculate_quality_score(
        self,
        result: Dict[str, Any],
        variant: Dict[str, Any]
    ) -> float:
        """
        è®¡ç®—è´¨é‡åˆ†æ•°

        Args:
            result: æ‰§è¡Œç»“æœ
            variant: ç­–ç•¥å˜ä½“

        Returns:
            è´¨é‡åˆ†æ•° (0-10)
        """
        # æƒé‡é…ç½®
        weights = {
            "code_quality": 0.3,
            "task_completion": 0.3,
            "agent_coordination": 0.2,
            "test_pass_rate": 0.2
        }

        # è®¡ç®—æµ‹è¯•é€šè¿‡ç‡
        tests_passed = result.get("tests_passed", 0)
        tests_failed = result.get("tests_failed", 0)
        total_tests = tests_passed + tests_failed
        test_pass_rate = (tests_passed / total_tests * 10) if total_tests > 0 else 8.0

        # åŠ æƒè®¡ç®—
        score = (
            result.get("code_quality", 8.0) * weights["code_quality"] +
            result.get("task_completion", 8.0) * weights["task_completion"] +
            result.get("agent_coordination", 7.0) * weights["agent_coordination"] +
            test_pass_rate * weights["test_pass_rate"]
        )

        # æ ¹æ®å¹¶è¡Œåº¦è°ƒæ•´åˆ†æ•°
        parallel_degree = variant.get("parallel_degree", "medium")
        if parallel_degree == "high":
            score *= 1.1  # é«˜å¹¶è¡Œåº¦åŠ åˆ†
        elif parallel_degree == "low":
            score *= 0.95  # ä½å¹¶è¡Œåº¦å‡åˆ†

        return min(10.0, max(0.0, score))

    def compare_results(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        å¯¹æ¯”ç»“æœï¼Œé€‰æ‹©æœ€ä¼˜ç­–ç•¥

        Args:
            results: æ‰§è¡Œç»“æœåˆ—è¡¨

        Returns:
            å¯¹æ¯”åˆ†æç»“æœ
        """
        print("\nğŸ“Š å¯¹æ¯”åˆ†æç»“æœ:\n")

        # è¿‡æ»¤æˆåŠŸçš„ç»“æœ
        successful_results = [r for r in results if r["success"]]

        if not successful_results:
            return {
                "best_variant": None,
                "best_score": 0,
                "analysis": "æ‰€æœ‰å˜ä½“æ‰§è¡Œå¤±è´¥",
                "all_results": results
            }

        # æ‰¾åˆ°æœ€ä½³å˜ä½“
        best_result = max(successful_results, key=lambda x: x["quality_score"])

        # æ‰“å°å¯¹æ¯”è¡¨æ ¼
        print("| å˜ä½“ID | å˜ä½“åç§° | å¾—åˆ† | è€—æ—¶(ç§’) | çŠ¶æ€ |")
        print("|--------|----------|------|----------|------|")
        for r in results:
            status = "âœ…" if r["success"] else "âŒ"
            print(f"| {r['variant_id']} | {r['variant_name'][:20]} | "
                  f"{r['quality_score']:.1f}/10 | {r['duration']:.2f} | {status} |")

        print(f"\nğŸ† æœ€ä½³å˜ä½“: {best_result['variant_name']} (å¾—åˆ†: {best_result['quality_score']:.1f}/10)")

        # åˆ†æä¼˜åŠ¿å’ŒåŠ£åŠ¿
        analysis = self._analyze_results(successful_results, best_result)

        return {
            "best_variant": best_result["variant_name"],
            "best_variant_id": best_result["variant_id"],
            "best_score": best_result["quality_score"],
            "analysis": analysis,
            "all_results": results
        }

    def _analyze_results(
        self,
        successful_results: List[Dict[str, Any]],
        best_result: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        åˆ†æç»“æœ

        Args:
            successful_results: æˆåŠŸçš„ç»“æœåˆ—è¡¨
            best_result: æœ€ä½³ç»“æœ

        Returns:
            åˆ†æç»“æœ
        """
        # è®¡ç®—å¹³å‡åˆ†æ•°
        avg_score = sum(r["quality_score"] for r in successful_results) / len(successful_results)

        # æå–ä¼˜åŠ¿
        strengths = []
        if best_result["quality_score"] > avg_score + 1:
            strengths.append("è´¨é‡æ˜¾è‘—é«˜äºå¹³å‡æ°´å¹³")
        if best_result["duration"] < 2.0:
            strengths.append("æ‰§è¡Œé€Ÿåº¦å¿«")

        # æå–åŠ£åŠ¿
        weaknesses = []
        if best_result["duration"] > 2.5:
            weaknesses.append("æ‰§è¡Œæ—¶é—´è¾ƒé•¿")

        # æå–æœ€ä½³å®è·µ
        best_practices = []
        config = best_result.get("config", {})
        if config.get("max_parallel_agents", 0) >= 3:
            best_practices.append("é€‚åº¦å¹¶è¡Œæå‡æ•ˆç‡")
        if config.get("task_granularity") == "fine":
            best_practices.append("ç»†ç²’åº¦ä»»åŠ¡åˆ†è§£æé«˜è´¨é‡")

        return {
            "avg_score": avg_score,
            "strengths": strengths,
            "weaknesses": weaknesses,
            "best_practices": best_practices
        }

    def _save_results(self, results: List[Dict[str, Any]], task_description: str):
        """
        ä¿å­˜æ‰§è¡Œç»“æœ

        Args:
            results: æ‰§è¡Œç»“æœåˆ—è¡¨
            task_description: ä»»åŠ¡æè¿°
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"execution_{timestamp}.json"
        filepath = self.results_dir / filename

        data = {
            "timestamp": timestamp,
            "task_description": task_description,
            "results": results
        }

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {filepath}")

    def update_strategy_weights(
        self,
        best_variant_name: str,
        best_score: float,
        weights_file: str = None
    ):
        """
        æ›´æ–°ç­–ç•¥æƒé‡ï¼ˆæŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼‰

        Args:
            best_variant_name: æœ€ä½³å˜ä½“åç§°
            best_score: æœ€ä½³åˆ†æ•°
            weights_file: æƒé‡æ–‡ä»¶è·¯å¾„
        """
        if weights_file is None:
            weights_file = Path(__file__).parent.parent / "strategy_weights.json"

        # è¯»å–ç°æœ‰æƒé‡
        if Path(weights_file).exists():
            with open(weights_file, 'r', encoding='utf-8') as f:
                weights = json.load(f)
        else:
            weights = {}

        # æå–ç­–ç•¥ç±»å‹ï¼ˆå»æ‰ _default åç¼€ï¼‰
        strategy_type = best_variant_name.replace("_default", "").replace("default_", "")

        # æ›´æ–°æƒé‡ï¼ˆæŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼Œalpha=0.3ï¼‰
        alpha = 0.3
        current_weight = weights.get(strategy_type, 5.0)
        new_weight = alpha * best_score + (1 - alpha) * current_weight

        weights[strategy_type] = round(new_weight, 2)
        weights["last_updated"] = datetime.now().isoformat()

        # ä¿å­˜æƒé‡
        with open(weights_file, 'w', encoding='utf-8') as f:
            json.dump(weights, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ“ˆ ç­–ç•¥æƒé‡å·²æ›´æ–°:")
        print(f"  {strategy_type}: {current_weight:.2f} â†’ {new_weight:.2f}")


async def main():
    """ä¸»å‡½æ•°"""
    executor = ParallelExecutor()

    # ç¤ºä¾‹å˜ä½“
    variants = [
        {
            "name": "default_parallel_high",
            "parallel_degree": "high",
            "config": {"max_parallel_agents": 5}
        },
        {
            "name": "default_granular",
            "parallel_degree": "medium",
            "config": {"max_parallel_agents": 3, "task_granularity": "fine"}
        },
        {
            "name": "default_sequential",
            "parallel_degree": "low",
            "config": {"max_parallel_agents": 1}
        },
        {
            "name": "default_hybrid",
            "parallel_degree": "adaptive",
            "config": {"max_parallel_agents": 3, "task_granularity": "adaptive"}
        }
    ]

    # æ‰§è¡Œ
    results = await executor.execute_variants(variants, "å®ç°ç”¨æˆ·ç™»å½•åŠŸèƒ½")

    # å¯¹æ¯”
    comparison = executor.compare_results(results)

    # æ›´æ–°æƒé‡
    if comparison["best_variant"]:
        executor.update_strategy_weights(
            comparison["best_variant"],
            comparison["best_score"]
        )

    # è¾“å‡ºå®Œæ•´ç»“æœ
    print("\nğŸ“‹ å®Œæ•´å¯¹æ¯”ç»“æœ:")
    print(json.dumps(comparison, indent=2, ensure_ascii=False))


if __name__ == "__main__":
    asyncio.run(main())
