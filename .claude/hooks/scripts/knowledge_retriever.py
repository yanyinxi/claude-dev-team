#!/usr/bin/env python3
"""
æ™ºèƒ½æ£€ç´¢æ¨¡å— - åŸºäºä¸Šä¸‹æ–‡æ£€ç´¢ç›¸å…³çŸ¥è¯†

åŠŸèƒ½ï¼š
1. åŸºäºä¸Šä¸‹æ–‡çš„æ™ºèƒ½æ£€ç´¢
2. å¤šç»´åº¦ç›¸å…³æ€§è®¡ç®—
3. ç»“æœæ’åºå’Œè¿‡æ»¤
4. ä¸ Hooks é›†æˆ
"""

import json
import sys
from pathlib import Path
from typing import List, Dict, Optional

# æ·»åŠ è„šæœ¬ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from knowledge_graph import KnowledgeGraph


class KnowledgeRetriever:
    """çŸ¥è¯†æ£€ç´¢å™¨"""

    def __init__(self, graph_file: str = ".claude/knowledge_graph.json"):
        """
        åˆå§‹åŒ–æ£€ç´¢å™¨

        Args:
            graph_file: çŸ¥è¯†å›¾è°±æ–‡ä»¶è·¯å¾„
        """
        self.kg = KnowledgeGraph(graph_file)

    def retrieve_relevant_knowledge(
        self,
        context: str,
        domain: Optional[str] = None,
        node_type: Optional[str] = None,
        top_k: int = 5
    ) -> List[Dict]:
        """
        åŸºäºä¸Šä¸‹æ–‡æ£€ç´¢ç›¸å…³çŸ¥è¯†

        Args:
            context: ä¸Šä¸‹æ–‡æ–‡æœ¬ï¼ˆå¦‚ä»»åŠ¡æè¿°ã€é—®é¢˜æè¿°ï¼‰
            domain: é¢†åŸŸè¿‡æ»¤ï¼ˆå¦‚ backend, frontendï¼‰
            node_type: èŠ‚ç‚¹ç±»å‹è¿‡æ»¤ï¼ˆå¦‚ best_practice, improvementï¼‰
            top_k: è¿”å›å‰ k ä¸ªç»“æœ

        Returns:
            list: ç›¸å…³çŸ¥è¯†èŠ‚ç‚¹åˆ—è¡¨
        """
        # æå–å…³é”®è¯
        keywords = self._extract_keywords(context)

        # æœç´¢ç›¸å…³èŠ‚ç‚¹
        all_results = []
        for keyword in keywords:
            results = self.kg.search_nodes(keyword, domain, node_type)
            all_results.extend(results)

        # å»é‡ï¼ˆåŸºäºèŠ‚ç‚¹ IDï¼‰
        seen_ids = set()
        unique_results = []
        for node in all_results:
            if node["id"] not in seen_ids:
                seen_ids.add(node["id"])
                unique_results.append(node)

        # é‡æ–°è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
        for node in unique_results:
            node["_final_score"] = self._calculate_relevance(node, context, keywords)

        # æ’åº
        unique_results.sort(key=lambda x: x.get("_final_score", 0), reverse=True)

        # è¿”å› top-k
        return unique_results[:top_k]

    def _extract_keywords(self, text: str) -> List[str]:
        """
        ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            list: å…³é”®è¯åˆ—è¡¨
        """
        import re

        # ç®€å•å®ç°ï¼šæå–é•¿åº¦ >= 3 çš„å•è¯
        words = re.findall(r'\w+', text.lower())
        keywords = [w for w in words if len(w) >= 3]

        # å»é‡å¹¶ä¿æŒé¡ºåº
        seen = set()
        unique_keywords = []
        for kw in keywords:
            if kw not in seen:
                seen.add(kw)
                unique_keywords.append(kw)

        return unique_keywords[:10]  # æœ€å¤š 10 ä¸ªå…³é”®è¯

    def _calculate_relevance(self, node: Dict, context: str, keywords: List[str]) -> float:
        """
        è®¡ç®—èŠ‚ç‚¹ä¸ä¸Šä¸‹æ–‡çš„ç›¸å…³æ€§

        Args:
            node: çŸ¥è¯†èŠ‚ç‚¹
            context: ä¸Šä¸‹æ–‡æ–‡æœ¬
            keywords: å…³é”®è¯åˆ—è¡¨

        Returns:
            float: ç›¸å…³æ€§åˆ†æ•°
        """
        score = 0.0

        # 1. å…³é”®è¯åŒ¹é…åˆ†æ•°
        title = node.get("title", "").lower()
        description = node.get("description", "").lower()
        tags = [t.lower() for t in node.get("tags", [])]

        for keyword in keywords:
            if keyword in title:
                score += 3.0
            if keyword in description:
                score += 1.5
            if any(keyword in tag for tag in tags):
                score += 2.0

        # 2. æˆåŠŸç‡åŠ æƒ
        success_rate = node.get("success_rate", 0)
        score += success_rate * 5.0

        # 3. å¹³å‡å¥–åŠ±åŠ æƒ
        avg_reward = node.get("avg_reward", 0)
        score += avg_reward * 0.5

        # 4. è¯æ®æ•°é‡åŠ æƒ
        evidence_count = len(node.get("evidence", []))
        score += min(evidence_count * 0.5, 2.0)  # æœ€å¤šåŠ  2 åˆ†

        return score

    def retrieve_by_domain(self, domain: str, top_k: int = 10) -> List[Dict]:
        """
        æŒ‰é¢†åŸŸæ£€ç´¢çŸ¥è¯†

        Args:
            domain: é¢†åŸŸåç§°
            top_k: è¿”å›å‰ k ä¸ªç»“æœ

        Returns:
            list: çŸ¥è¯†èŠ‚ç‚¹åˆ—è¡¨
        """
        results = []
        for node in self.kg.graph["nodes"]:
            if node.get("domain") == domain:
                results.append(node)

        # æŒ‰æˆåŠŸç‡æ’åº
        results.sort(key=lambda x: x.get("success_rate", 0), reverse=True)

        return results[:top_k]

    def retrieve_by_type(self, node_type: str, top_k: int = 10) -> List[Dict]:
        """
        æŒ‰ç±»å‹æ£€ç´¢çŸ¥è¯†

        Args:
            node_type: èŠ‚ç‚¹ç±»å‹
            top_k: è¿”å›å‰ k ä¸ªç»“æœ

        Returns:
            list: çŸ¥è¯†èŠ‚ç‚¹åˆ—è¡¨
        """
        results = []
        for node in self.kg.graph["nodes"]:
            if node.get("type") == node_type:
                results.append(node)

        # æŒ‰æˆåŠŸç‡æ’åº
        results.sort(key=lambda x: x.get("success_rate", 0), reverse=True)

        return results[:top_k]

    def retrieve_related(self, node_id: str, relation: Optional[str] = None) -> List[Dict]:
        """
        æ£€ç´¢ç›¸å…³èŠ‚ç‚¹

        Args:
            node_id: èŠ‚ç‚¹ ID
            relation: å…³ç³»ç±»å‹ï¼ˆå¯é€‰ï¼‰

        Returns:
            list: ç›¸å…³èŠ‚ç‚¹åˆ—è¡¨
        """
        return self.kg.find_related_nodes(node_id, relation)

    def format_results(self, results: List[Dict], include_score: bool = True) -> str:
        """
        æ ¼å¼åŒ–æ£€ç´¢ç»“æœä¸ºå¯è¯»æ–‡æœ¬

        Args:
            results: æ£€ç´¢ç»“æœåˆ—è¡¨
            include_score: æ˜¯å¦åŒ…å«åˆ†æ•°

        Returns:
            str: æ ¼å¼åŒ–åçš„æ–‡æœ¬
        """
        if not results:
            return "æœªæ‰¾åˆ°ç›¸å…³çŸ¥è¯†"

        lines = ["ğŸ“š ç›¸å…³çŸ¥è¯†ï¼š\n"]

        for i, node in enumerate(results, 1):
            title = node.get("title", "Untitled")
            description = node.get("description", "")
            success_rate = node.get("success_rate", 0)
            avg_reward = node.get("avg_reward", 0)

            lines.append(f"{i}. **{title}**")

            if include_score and "_final_score" in node:
                lines.append(f" (ç›¸å…³æ€§: {node['_final_score']:.1f})")

            lines.append(f"\n   - æè¿°: {description}")
            lines.append(f"\n   - æˆåŠŸç‡: {success_rate:.0%}")
            lines.append(f"\n   - å¹³å‡å¥–åŠ±: {avg_reward:.1f}/10")

            tags = node.get("tags", [])
            if tags:
                lines.append(f"\n   - æ ‡ç­¾: {', '.join(tags)}")

            lines.append("\n\n")

        return "".join(lines)


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    # ä» stdin è¯»å–è¾“å…¥
    try:
        input_data = json.load(sys.stdin)
    except json.JSONDecodeError:
        print("Error: Invalid JSON input", file=sys.stderr)
        sys.exit(1)

    context = input_data.get("context", "")
    domain = input_data.get("domain")
    node_type = input_data.get("type")
    top_k = input_data.get("top_k", 5)

    if not context:
        print("Error: 'context' field is required", file=sys.stderr)
        sys.exit(1)

    # æ£€ç´¢çŸ¥è¯†
    retriever = KnowledgeRetriever()
    results = retriever.retrieve_relevant_knowledge(context, domain, node_type, top_k)

    # è¾“å‡ºç»“æœ
    if results:
        output = retriever.format_results(results)
        print(output)
    else:
        print("æœªæ‰¾åˆ°ç›¸å…³çŸ¥è¯†")

    sys.exit(0)


if __name__ == "__main__":
    main()
